# CaptainAgent Paper

论文总结：Adaptive In-conversation Team Building for Language Model Agents

本文提出了一种**自适应对话内团队构建范式**及实现该范式的智能体——Captain Agent，旨在解决多大型语言模型（LLM）智能体团队在复杂任务中“静态构建局限”的核心问题，通过动态组建、管理智能体团队，在多场景下实现了优于现有方法的性能，且无需任务特定的提示工程。


## 一、研究背景与核心问题
### 1. 背景
- 多LLM智能体系统已成为解决复杂任务的重要方向（如推理、规划、工具使用），但其设计仍依赖“经验”：现有方法多采用**静态团队构建**（提前根据任务指令组建固定团队），需覆盖任务全周期的所有 expertise，导致团队规模膨胀、管理效率低，且无法应对任务动态变化（如突发子任务需求）。
- 人类解决复杂任务的启发：人类会为任务不同阶段的子任务组建专属团队（如部落中狩猎、医疗、烹饪分工），而非全员参与所有任务，这为自适应团队构建提供了思路。

### 2. 核心问题
给定一个复杂任务，如何**动态组建和管理LLM智能体团队**，以高效利用多样化 expertise、避免冗余输出，同时无需依赖任务特定的人工设计？


## 二、Captain Agent的核心设计
Captain Agent通过“自适应多智能体团队构建”和“嵌套群组对话与反思”两大组件，实现动态任务拆解与团队管理，整体工作流如图1所示（用户与Captain Agent为主对话，团队解决子任务为嵌套对话）。

### 1. 组件1：自适应多智能体团队构建（Step 1）
针对当前子任务，Captain Agent通过“检索-过滤-生成”三步组建团队，并维护团队记忆，具体流程：
- **检索（Agent & Tool Retrieval）**：基于子任务所需角色（如“数据分析专家”），通过嵌入相似度从**智能体库（A_lib）** 和**工具库（T_lib）** 中分别检索Top-k₁智能体和Top-k₂工具（工具含数学计算、数据分析、信息检索等预定义Python函数）。
- **过滤（Agent Filtering）**：用LLM过滤器从候选智能体中筛选Top-1最适配者，若无适配智能体则触发“生成”步骤（避免无关智能体加入）。
- **生成（Agent Generation）**：为无适配智能体的角色生成新智能体，步骤包括：①生成基础档案（名称、角色、技能）；②结合通用任务指令（如群组对话规则）；③绑定检索到的工具，并将新智能体存入A_lib供后续复用。
- **团队记忆（Team Memory）**：缓存已组建团队的基础信息（无对话历史），后续相同子任务可直接调用，降低成本。

### 2. 组件2：嵌套群组对话与反思（Step 2）
团队组建后，通过“嵌套对话解决子任务+反思反馈优化”闭环，确保任务质量：
- **嵌套对话（Nested Conversation）**：独立于主对话，由LLM对话管理器根据历史动态选择下一个发言智能体，所有智能体共享嵌套对话历史（无法访问主对话），可通过Python代码块调用工具或扩展功能（如用已有工具创建新工具）。
- **对话反思（Conversation Reflection）**：嵌套对话结束后，由LLM反思器（Reflector）总结对话历史、检测争议（如智能体观点冲突），生成反思报告反馈给Captain Agent。Captain Agent基于报告决定：①调整团队/子任务指令后重试；②任务完成并输出结果。


## 三、实验设计与核心结果
### 1. 实验设置
- **场景与数据集**：覆盖6个真实场景，验证Captain Agent的通用性，具体如下：
  | 场景                | 数据集          | 任务示例                                  | 数据量 |
  |---------------------|-----------------|-------------------------------------------|--------|
  | 数学解题            | MATH            | 求解代数方程（排除x=1时m的不可取值）      | 196    |
  | 编程                | HumanEval       | 实现浮点数截断函数并通过单元测试          | 164    |
  | 数据分析            | DABench         | 生成“家庭规模”特征并计算其与“票价”的相关性 | 257    |
  | 信息检索            | GAIA            | 查找BBC地球视频中“最傻动物时刻”的鸟类物种 | 165    |
  | 科学（化学）        | SciBench        | 计算氮气在特定条件下的压强                | 41     |
  | 科学（物理）        | SciBench        | 计算滑块开始滑动的斜面角度                | 34     |
- **基线方法**：对比Vanilla LLM（单LLM单次查询）、AutoAgents、Meta-prompting、AgentVerse、DyLAN、AutoGen双智能体（Assistant+Executor）等8种方法，且所有方法使用相同任务指令（保证公平性）。
- **骨干LLM**：主要使用gpt-4-0125-preview，额外测试gpt-4o-mini、LLaMA-3-70B/8B以验证模型兼容性。

### 2. 核心结果
Captain Agent在所有场景中表现最优，平均准确率较基线提升**21.94%**，关键结果如下：
- **多场景性能**：在数学（77.55% vs 基线最高74.49%）、编程（96.95% vs 基线最高93.90%）、数据分析（88.32% vs 基线最高82.88%）等场景中均超越所有基线。
- **信息检索性能**：在GAIA数据集上，平均准确率达40.60%，超越AutoGen GAIA Orchestrator（39.39%）、FRIDAY（34.55%）等Top基线。
- **弱模型兼容性与成本优势**：使用gpt-4o-mini（小模型）的Captain Agent，性能优于使用gpt-4的多数基线，且成本显著降低（如数学任务成本仅为AutoAgent的1/20）。


## 四、关键发现与消融分析
通过消融实验验证了Captain Agent各组件的必要性，及自适应范式的优势：

### 1. 自适应vs静态团队
- 自适应团队在5个场景中的4个表现更优（仅物理场景持平），其中数据分析场景准确率提升超30.43%，证明动态调整团队能更好适配子任务需求，避免静态团队的冗余与能力局限。

### 2. 智能体库与工具库的作用
- 移除任一库都会显著降低性能：无库时GAIA平均准确率仅18.18%，仅用智能体库为29.09%，仅用工具库为24.24%，而两者结合时达40.60%。尤其Level 2信息检索任务（需多工具协同），无智能体库时性能骤降，证明团队多样性的重要性。

### 3. 反思机制的必要性
- 加入反思机制后，所有场景性能均提升，尤其物理场景（反思器成功检测争议并避免错误传播），反思器的争议识别成功率直接影响多轮任务的正确性。

### 4. 智能体选择的场景相关性
- 各场景选择的Top-10智能体高度匹配任务需求：如信息检索场景中“WebResearch Expert”被高频选择，数学场景中“PythonMath Expert”“Verification Expert”占比最高，证明团队构建的针对性。


## 五、局限与未来方向
### 1. 当前局限
- **成本问题**：尽管复用团队降低成本，但GPT-4等大模型的对话仍比单智能体系统昂贵，需探索上下文窗口优化、对话压缩等方案。
- **模型选择与数据泄露**：未深入研究模型选择策略，且LLM预训练数据泄露可能导致测试性能与真实场景偏差。
- **通用性局限**：基于AutoGen框架实现，难以兼容其他手工设计的智能体，需制定通用智能体通信协议。

### 2. 未来方向
- 优化性能与成本的权衡，探索小模型作为骨干的潜力；
- 设计通用智能体通信协议，扩展Agent库兼容性；
- 加强动态模型选择与抗数据泄露的评估方法。


## 六、核心贡献
1. **范式创新**：提出“自适应对话内团队构建”范式，打破静态团队的局限，实现子任务级的动态团队管理。
2. **系统设计**：设计Captain Agent，通过“检索-过滤-生成”团队构建与“嵌套对话+反思”机制，兼顾灵活性与结构化。
3. **性能验证**：在6个真实场景中实现21.94%的平均准确率提升，且弱模型可低成本达到竞争力，为多智能体系统的实用化提供思路。